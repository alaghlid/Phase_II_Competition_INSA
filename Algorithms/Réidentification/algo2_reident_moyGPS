from os import name
import pandas as pd
import csv
import json
from math import *
import datetime

#### ______________________________________________________________________________________________________________________
## Equipe : ALANOZY
## Membres :
#           - LAGHLID Ayoub.
#           - ZKIM Youssef.
#### ______________________________________________________________________________________________________________________

###########################################################################################################################
## Cette fonction sert à réidentifier les individus en générant un fichier Json qui contiendra les guesses.
## Cet attaque est conçu pour les équipes qui modifient le GPS (longitude - latittude), le principe est basé sur le calcule de la moyenne de GPS
###########################################################################################################################

# Path de la base originale (à changer)
path_originale = "INSAnonym/c3465dad3864bb1e373891fdcfbfcca5f974db6a9e0b646584e07c5f554d7df7"

# Path de la base anonymisée (à changer)
path_anonymisee = "/media/alaghlid/Disque/Attack Dbs/dbm/files/S_user_40_2cda2307d8c8d01b3885a20a7d22f25eccfa2d8c319c85521c3b1947994c4b82"

# Path du fichier JSON généré (à changer)
json_guesses = '../dbm.json'


def alanozy_reident():
    ## Lire le fichier CSV de la base anonymisée
    df_anonym = pd.read_csv(path_anonymisee, sep="\t", header=None).set_axis(
        ['QId', 'Date', 'longitude', 'lattitude'], axis=1, inplace=False)

    ## Extraction des lignes non supprimées
    df_anonym = df_anonym[df_anonym['QId'] != 'DEL']

    df_anonym['Date'] = pd.to_datetime(
        df_anonym['Date'], errors='coerce', dayfirst=True)
    df_anonym['week'] = df_anonym['Date'].dt.strftime('%Y-%W')

    ## Lire le fichier CSV de la base originale
    df_originale = pd.read_csv(path_originale, sep="\t", header=None).set_axis(
        ['Id', 'Date', 'longitude', 'lattitude'], axis=1, inplace=False)
    df_originale['Date'] = pd.to_datetime(
        df_originale['Date'], errors='coerce', dayfirst=True)
    df_originale['week'] = df_originale['Date'].dt.strftime('%Y-%W')

    ## Création des fichiers orig/ano pour chaque semaine
    i = 0
    for week in df_originale['week'].unique():
        df_originale[df_originale['week'] == week].to_csv(
            f'../fichiers_weeks_orig/week_{week}.csv', header=False, index=False, sep='\t')
        df_anonym[df_anonym['week'] == week].to_csv(
            f'../fichiers_weeks_ano/week_{week}.csv', header=False, index=False, sep='\t')
        i += 1

    ## récupération de la liste des semaines (weeks)
    weeks = df_originale['week'].unique()

    df_originale_week = df_originale.drop(columns=['week'])
    df_anonym_week = df_anonym.drop(columns=['week'])

    ## récupération des Ids
    ids = df_originale['Id'].unique()

    ## Création de guesses_reident qui contient le guesse de chaque individu existant dans chaque semaine
    guesses_reident = {}
    for id in ids:
        guesses_reident[str(id)] = {}
    for week in weeks:
        df_originale_week = pd.read_csv(f'../fichiers_weeks_orig/week_{week}.csv', sep='\t', names=[
            "id", "date", "latittude", "longitude", "week"]).set_index('date')
        df_anonym_week = pd.read_csv(f'../fichiers_weeks_ano/week_{week}.csv', sep='\t', names=[
            "pseudo_Id", "date", "latittude", "longitude", "week"]).set_index('date')
        
        ## Nombres de lignes supprimées dans la semaine 
        nb_lignes_supp = len(df_originale_week)-len(df_anonym_week)

        df_originale_week = df_originale_week.groupby(['id'])[['latittude', 'long']].aggregate(['count', 'mean']).reset_index()
        df_anonym_week = df_anonym_week.groupby(['pseudo_id'])[['latittude', 'long']].aggregate(['count', 'mean']).reset_index()
        for id in ids:
            guesses_reident[str(id)][str(week)] = []
        
        if nb_lignes_supp == 0:  # Aucune ligne supprimée => Réidentification par le comptage des lignes 
            for index, row in df_originale_week.iterrows():
                for index1, row1 in df_anonym_week.iterrows():
                    if df_originale_week['latittude']['count'][index] == df_anonym_week['latittude']['count'][index1]: ## Egalité des occurences du couple : (id, pseudo_id) => Pseudo_Id est sûrement le guesse de cet Id
                        guesses_reident[str(df_originale_week['id'][index])][week].append(
                            str(df_anonym_week['pseudo_id'][index1]))
        else:  # Des lignes sont supprimées donc on procède à notre méthode de moyenne
            x = 0
            for index, row in df_originale_week.iterrows():
                dist_gps = {}
                dist_gps[str(df_originale_week['id'][index])] = []
                I = str(df_originale_week['id'][index])
                pseudo_ids = []
                for index1, row1 in df_anonym_week.iterrows():
                    if (df_originale_week['latittude']['count'][index] >= df_anonym_week['latittude']['count'][index1] and df_originale_week['latittude']['count'][index] <= df_anonym_week['latittude']['count'][index1]+nb_lignes_supp):
                        dist_gps[I].append(sqrt((df_originale_week['latittude']['mean'][index]-df_anonym_week['latittude']['mean'][index1])**2 + (df_originale_week['long']['mean'][index]-df_anonym_week['long']['mean'][index1])**2))
                        pseudo_ids.append(str(df_anonym_week['pseudo_id'][index1]))
                df = pd.DataFrame.from_dict(dist_gps, orient='index', columns=pseudo_ids)
                df = df.transpose()
                ## On prend un seul guesse le plus proche (on peut changer le nombre des guesses)
                ordered = df.nsmallest(1, str(df_originale_week['id'][index]))
                guesses_list = ordered.index.tolist()

                # Ajout du guesse dans guesses_reident
                guesses_reident[str(df_originale_week['id'][index])][week].extend(guesses_list)

        print(f"Réidentification terminée pour la semaine {week}")

    ## Génération du fichier JSON en écrivant le contenu de guesses_reident
    with open(json_guesses, 'w') as f:
        json.dump(guesses_reident, f)


alanozy_reident()
